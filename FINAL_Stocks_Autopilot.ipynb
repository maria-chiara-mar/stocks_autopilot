{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maria-chiara-mar/stocks_autopilot/blob/main/FINAL_Stocks_Autopilot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script uses the GitHub library EdgarTools to extract companies' financial information from the US SEC database EDGAR, transforms them into data-frames (**Step 1**), and plugs the info in the corresponding location in the company google sheet (**Step 4**). The Google Sheet is used for modeling future cash flows and calculating the price per share of different companies. It finds the correct location in the google sheet with the help of a dictionary, created in the google sheet (**Step 2**). Optionaly, you can export the transformed data into the google sheet (**Step 3**)."
      ],
      "metadata": {
        "id": "j1jglq_51VfJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Step 0**\n",
        "Installs the package, and imports all relevant libraries, functions, authentifications."
      ],
      "metadata": {
        "id": "wiZhQHGruQdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Insalls GitHub library EdgarTools\n",
        "!pip install edgartools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Z06c_RIv1kdy",
        "outputId": "f1f04e49-af4b-4eb9-d9ff-a89d8d4b3e1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting edgartools\n",
            "  Downloading edgartools-5.0.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: beautifulsoup4>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from edgartools) (4.13.5)\n",
            "Collecting hishel==0.1.3 (from edgartools)\n",
            "  Downloading hishel-0.1.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from edgartools) (0.28.1)\n",
            "Collecting httpxthrottlecache>=0.1.6 (from edgartools)\n",
            "  Downloading httpxthrottlecache-0.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: humanize>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from edgartools) (4.14.0)\n",
            "Requirement already satisfied: jinja2>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from edgartools) (3.1.6)\n",
            "Requirement already satisfied: lxml>=4.4 in /usr/local/lib/python3.12/dist-packages (from edgartools) (6.0.2)\n",
            "Requirement already satisfied: nest-asyncio>=1.5.1 in /usr/local/lib/python3.12/dist-packages (from edgartools) (1.6.0)\n",
            "Requirement already satisfied: orjson>=3.6.0 in /usr/local/lib/python3.12/dist-packages (from edgartools) (3.11.4)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from edgartools) (2.2.2)\n",
            "Requirement already satisfied: pyarrow>=17.0.0 in /usr/local/lib/python3.12/dist-packages (from edgartools) (18.1.0)\n",
            "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from edgartools) (2.12.3)\n",
            "Collecting rank-bm25>=0.2.1 (from edgartools)\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting rapidfuzz>=3.5.0 (from edgartools)\n",
            "  Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: rich>=13.8.0 in /usr/local/lib/python3.12/dist-packages (from edgartools) (13.9.4)\n",
            "Collecting stamina>=24.2.0 (from edgartools)\n",
            "  Downloading stamina-25.2.0-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: tabulate>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from edgartools) (0.9.0)\n",
            "Collecting textdistance>=4.5.0 (from edgartools)\n",
            "  Downloading textdistance-4.6.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: tqdm>=4.62.0 in /usr/local/lib/python3.12/dist-packages (from edgartools) (4.67.1)\n",
            "Collecting unidecode>=1.2.0 (from edgartools)\n",
            "  Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.10.0->edgartools) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.10.0->edgartools) (4.15.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.0->edgartools) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.0->edgartools) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.0->edgartools) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.0->edgartools) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.0->edgartools) (0.16.0)\n",
            "Requirement already satisfied: aiofiles>=24.1.0 in /usr/local/lib/python3.12/dist-packages (from httpxthrottlecache>=0.1.6->edgartools) (24.1.0)\n",
            "Requirement already satisfied: filelock>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from httpxthrottlecache>=0.1.6->edgartools) (3.20.0)\n",
            "Collecting pyrate-limiter>=3.9.0 (from httpxthrottlecache>=0.1.6->edgartools)\n",
            "  Downloading pyrate_limiter-3.9.0-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=3.1.0->edgartools) (3.0.3)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->edgartools) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->edgartools) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->edgartools) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->edgartools) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->edgartools) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->edgartools) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0.0->edgartools) (0.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.8.0->edgartools) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.8.0->edgartools) (2.19.2)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.12/dist-packages (from stamina>=24.2.0->edgartools) (9.1.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.8.0->edgartools) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->edgartools) (1.17.0)\n",
            "Downloading edgartools-5.0.2-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hishel-0.1.3-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpxthrottlecache-0.3.0-py3-none-any.whl (13 kB)\n",
            "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Downloading rapidfuzz-3.14.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stamina-25.2.0-py3-none-any.whl (18 kB)\n",
            "Downloading textdistance-4.6.3-py3-none-any.whl (31 kB)\n",
            "Downloading Unidecode-1.4.0-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.8/235.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyrate_limiter-3.9.0-py3-none-any.whl (33 kB)\n",
            "Installing collected packages: unidecode, textdistance, stamina, rapidfuzz, rank-bm25, pyrate-limiter, httpxthrottlecache, hishel, edgartools\n",
            "Successfully installed edgartools-5.0.2 hishel-0.1.3 httpxthrottlecache-0.3.0 pyrate-limiter-3.9.0 rank-bm25-0.2.2 rapidfuzz-3.14.3 stamina-25.2.0 textdistance-4.6.3 unidecode-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# EdgarTools imports\n",
        "from edgar import *\n",
        "from edgar.xbrl import XBRLS\n",
        "set_identity(\"kindemilvc@gmail.com\") #email address here (auth for SEC)\n",
        "\n",
        "# Pandas / Datetime import\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# Gspread for google sheet manipulation\n",
        "import gspread\n",
        "from gspread_dataframe import set_with_dataframe\n",
        "\n",
        "# Google authentification to access google sheets\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "google_sheet_name = \"Stonks 3.0\" # <-- put here name of the google sheet (relevant for Steps 2, 3, 4 with google sheet interactions)\n"
      ],
      "metadata": {
        "id": "TPBWBbwLqUcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Step 1**\n",
        "The three financial statements are called, transformed, unpivoted, and appended to one flat dataframe\n",
        "- Cashflow: extract stitched_statement to retrieve information on several years;\n",
        "- Balance Sheet: same as above;\n",
        "- Income Statement: extract the full statement to retrieve very precise and highly granular information, but atm we are only able to export last 3 years;"
      ],
      "metadata": {
        "id": "8Xr7LA8np1dP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_company_data(ticker, years):\n",
        "\n",
        "  c = Company(ticker)\n",
        "  tenk = c.get_filings(form=\"10-K\") # get annual reports only\n",
        "\n",
        "  # for income statement - has detailed revenue breakdowns\n",
        "  latest = tenk.latest() # limited to last 3 years\n",
        "  xb = latest.xbrl()\n",
        "  inc = xb.statements.income_statement()\n",
        "\n",
        "  # for balance sheet and cash flow\n",
        "  latest2 = tenk.latest(years) # get x years of historical data\n",
        "  xb_years = XBRLS.from_filings(latest2)\n",
        "  stitched_statements = xb_years.statements # merge historical years\n",
        "  bs = xb_years.statements.balance_sheet()\n",
        "  cf = xb_years.statements.cashflow_statement()\n",
        "\n",
        "  # transformed into dataframes\n",
        "  df_inc = inc.to_dataframe()\n",
        "  df_bs = bs.to_dataframe()\n",
        "  df_cf = cf.to_dataframe()\n",
        "\n",
        "  # append the three stratements and drop unnecessary columns\n",
        "  df = pd.concat([df_inc, df_bs, df_cf])\n",
        "  df = df.drop(columns = [\"level\",\"abstract\",\"dimension\",\"balance\",\"weight\",\"preferred_sign\",\"parent_concept\"])\n",
        "  df['ticker'] = ticker # add ticker column\n",
        "\n",
        "  print(\"Extracted company data\")\n",
        "\n",
        "  return df\n",
        "\n",
        "def unpivot_df(df):\n",
        "  # unpivot date and value columns to get flat file format\n",
        "  columns_tokeep = [\"ticker\", 'concept', 'label']\n",
        "  columns_tomelt = [col for col in df.columns if col not in columns_tokeep]\n",
        "  df = pd.melt(df, id_vars=columns_tokeep, value_vars=columns_tomelt, var_name='date', value_name='value')\n",
        "\n",
        "  print(\"Unpivoted company data\")\n",
        "\n",
        "  return df\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nORuBNCio1Nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 2**\n",
        "Merge your unpivoted df with the google sheet \"Dictionary\", which contains the financial terms we use in our workframe. This step is necessary to plug-in the extracted data at the correct location."
      ],
      "metadata": {
        "id": "DEIawNOeqSDe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def import_dictionary(df_financials):\n",
        "  # find dictionary\n",
        "  sh = gc.open(google_sheet_name) # <-- put here name of the google sheet (relevant for Steps 2, 3, 4 with google sheet interactions)\n",
        "  worksheet = sh.worksheet('Dictionary') # sh. worksheet was already defined and opened in Step 0\n",
        "\n",
        "  # gets all values from the worksheet\n",
        "  data_list = worksheet.get_all_values()\n",
        "\n",
        "  # create a dataframe from the list of lists, using the first row as headers\n",
        "  df_dictionary = pd.DataFrame(data_list[1:], columns=data_list[0])\n",
        "\n",
        "  # gets rid of other columns if accidentaly imported\n",
        "  columns_tokeep = [\"ticker\", \"concept\", \"label\", \"name\"]\n",
        "  df_dictionary = df_dictionary[columns_tokeep]\n",
        "\n",
        "  # joins df_dictionary and combined financial statements (inner merge)\n",
        "  common_keys = ['ticker', 'concept', 'label']\n",
        "  df_final = pd.merge(df_financials, df_dictionary, on=common_keys, how='inner')\n",
        "\n",
        "  print(\"Merged with dictionary\")\n",
        "\n",
        "  return df_final"
      ],
      "metadata": {
        "id": "lmyxhZvTi8GH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 3 - OPTIONAL**\n",
        "Export your final DF to the Statements Database sheet, which will serve as your database for further analysis. Eliminate all manual steps by using the gspread automation."
      ],
      "metadata": {
        "id": "KH2QzPb1spnP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d12e483"
      },
      "source": [
        "def export_to_gsheet(df_final):\n",
        "  # opens the target google sheet (must already exist)\n",
        "  sh = gc.open(google_sheet_name) # <-- put here name of the google sheet (relevant for Steps 2, 3, 4 with google sheet interactions)\n",
        "  target_sheet_name = 'Edgar'\n",
        "  worksheet = sh.worksheet(target_sheet_name) # sh. worksheet was already defined and opened in Step 0\n",
        "\n",
        "  # clears existing content in the target sheet before uploading new data\n",
        "  worksheet.clear()\n",
        "\n",
        "  # uploads the df_final to the selected worksheet\n",
        "  set_with_dataframe(worksheet, df_final, include_index=False, include_column_header=True)\n",
        "\n",
        "  print(\"Exported to Google Sheet\")\n",
        "\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 4**\n",
        "Plugs the extracted financials to the correct location in the corresponding company google sheet."
      ],
      "metadata": {
        "id": "n7ZuUL5ptClJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plugging_in_gsheet(df_final):\n",
        "  # opens the company google sheet\n",
        "  sh = gc.open(google_sheet_name) # <-- put here name of the google sheet (relevant for Steps 2, 3, 4 with google sheet interactions)\n",
        "  ticker = df_final.iloc[0][\"ticker\"]\n",
        "  worksheet = sh.worksheet(ticker) # sh. worksheet was already defined and opened in Step 0\n",
        "\n",
        "  # defines sheet_ranges where to find row-/column index outside of the loop\n",
        "  range_date = worksheet.get(\"K3:ZZ4\")\n",
        "  range_row = worksheet.get(\"C:C\")\n",
        "\n",
        "  # loops through each row of the dataframe from step 2 - each row is one data point from the company financials\n",
        "  for rows in df_final.iterrows():\n",
        "\n",
        "    # FIND DATE IN LIST OF DATES FROM GS\n",
        "    hist_horizon = int(range_date[1][0].strip(\"()\")) # from google sheets extracts how many historical years we have\n",
        "    date_list = []\n",
        "    count = 0\n",
        "    for row in range_date:\n",
        "      if count > hist_horizon: break\n",
        "      for cell in row:\n",
        "        #cell = datetime.strptime(cell,\"%b/%Y\")\n",
        "        date_list.append(cell)\n",
        "        count = count +1\n",
        "        if count > hist_horizon:\n",
        "          break\n",
        "    # GET DATE (COLUMN) INDEX\n",
        "    df_date = rows[1][\"date\"]\n",
        "    df_date = datetime.strptime(df_date,\"%Y-%m-%d\")\n",
        "    date_index = date_list.index(df_date.strftime(\"%b/%Y\")) + 11 # column K-column C\n",
        "\n",
        "    # GET ROW INDEX\n",
        "    name = [rows[1][\"name\"]]\n",
        "    row_index = 0\n",
        "    for row in range_row:\n",
        "      row_index = row_index + 1\n",
        "      if row == name:\n",
        "        break\n",
        "\n",
        "    # transforms value to millions\n",
        "    value = rows[1][\"value\"]/10**6\n",
        "\n",
        "    # plugs in each row value into the correct date/column, and row index\n",
        "    worksheet.update_cell(row_index, date_index, value)\n",
        "\n",
        "  print(\"Inserted data points into google sheet\")\n",
        "\n",
        "  return\n"
      ],
      "metadata": {
        "id": "DwwrgPFRfMPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Execution** Calls the relevant functions for ticker x for y years"
      ],
      "metadata": {
        "id": "WE4PYg4QtShD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ticker = \"HUBS\"\n",
        "years = 3\n",
        "\n",
        "# Step 1 - gets company data\n",
        "df_financials = get_company_data(ticker, years) # execute only this function to get pivoted data - good for dictionary preparation\n",
        "df_financials_flat = unpivot_df(df_financials) # just unpivots the data\n",
        "\n",
        "# Step 2 - merges with dictionary\n",
        "df_final = import_dictionary(df_financials_flat)\n",
        "\n",
        "# Steps 3 (optional) - export df to google sheet\n",
        "export_to_gsheet(df_financials_flat)\n",
        "\n",
        "# Step 4 - plugs in data into company google sheet\n",
        "plugging_in_gsheet(df_final)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IYKFpK_cqGdt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "340e86f1-6501-476f-d9d7-6e58c3480f78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted company data\n",
            "Unpivoted company data\n",
            "Merged with dictionary\n",
            "Exported to Google Sheet\n",
            "Inserted data points into google sheet\n"
          ]
        }
      ]
    }
  ]
}